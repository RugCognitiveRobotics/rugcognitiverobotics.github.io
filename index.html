<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Cognitive Robotics Course</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="icon" href="images/favicon.ico">
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="https://www.rug.nl/ocasys/rug/vak/show?code=WMAI19001" target="_blank" class="logo"><strong>Cognitive Robotics Course (WMAI19001)</strong> - Hamidreza Kasaei </a>
									<ul class="icons">
										<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon fa-medium"><span class="label">Medium</span></a></li>
									</ul>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Cognitive Robotics</h1>											
										</header>
										<p style="text-align: justify; color: rgb(0, 0, 0);">Cognitive robots are expected to be more autonomous and efficiently work in human-centric environments. For these robots, 
											open-ended learning for object perception and grasping is a challenging task due to the high demand for accurate and real-time response under changing and unpredictable environmental conditions. 
											In this course, “open-ended” implies that the set of object categories to be learned is not known in advance, and the training instances are extracted from online experiences of a robot, and become gradually 
											available over time, rather than being completely available at the beginning of the learning process. This way the robot adapts its perception and grasping skills over time to different environments. 
											</br></br>
											This course covers a diverse set of topics that focus on addressing the most critical aspects of building a cognitive robotic system. Students will practice essential research skills including put
											hands-on experiences, debating, reviewing and critiquing papers, and presenting ideas effectively.
										</p> 
										<b style="color: rgb(255, 0, 25);">*Remark:</b> The course unit prepares students to do their graduation project if they choose to do it in robotics.
										<!--<ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul>-->
									</div>
									<span class="image fit">
										<img src="images/pic10.jpg"/>
									</span>
								</section>

								<section id="CS">
									<header class="major">
										<h2 id="OR">Coordinator</h2>
									</header>
									<div class="content">
										<article>
											<div class="content">
												<p> </p>
												<p style="text-align: justify;"><span class="image left"><img src="images/hamidreza.png" alt=""></span>	
													<h3> <a href="http://www.ai.rug.nl/hkasaei" target="_blank" style="color: rgb(0,0, 0);">Dr. Hamidreza Kasaei</a></h3>
													<p style="text-align: justify;">My research interest lies at the intersection of machine learning, robotics, and machine
													vision, particularly in the area of open-ended learning, 3D object perception, grasp
													affordance detection, and object manipulation. My goal is to achieve a breakthrough in robotics by
													enabling robots to learn from past experiences incrementally and safely interact with human users.
													I have been investigating on active perception, where robots use their mobility and manipulation capabilities not only
													to gain useful perceptual information but also to predict the next-best-view for improving the performance of
													object detection and manipulation. I have evaluated my works on different
													robotic platforms, including PR2, robotic arms (UR5e, Franka, Kinova), and humanoid
													robots. I am leading the <a href="https://www.ai.rug.nl/irl-lab/" target="_blank" style="color: rgb(0,0, 150);">Interactive Robot Learning Laboratory (IRL-Lab)</a> focusing on Lifelong Interactive Robot Learning in the areas of 3D Object Perception, Grasp Affordance, and Object Manipulation.																								
													Navigate <a href="http://www.ai.rug.nl/hkasaei" target="_blank" style="color: rgb(0,0, 150);"> my webpage </a> and 								
													<a href="https://www.ai.rug.nl/irl-lab/" target="_blank" style="color: rgb(0,0, 150);">IRL-Lab page</a>
													if you want to know more about my research.
													
													<p style="text-align: justify; color: rgb(0, 0, 0);">
													I developed the "Cognitive Robotics" course from scratch in 2019 and improving its content constantly.	
													This course covers a diverse set of topics that focus on addressing the most critical aspects of building a cognitive robotic system. 
													We recently wrote a survey paper about the state of lifelong learning in service robots that has been published in Journal of Intelligent & Robotic Systems (see https://arxiv.org/abs/2003.08151). 
													This survey paper covers all the topics of the cognitive robotics course in a concise and brief manner to help students in easy remembrance 
													and quick revision. I will try to share my knowledge with you throughout the course!
													<!-- , in which 75 students participated actively
													in both theoretical and practical sessions of the course. It is my pleasure that the students were satisfied with the content
													of the course and assessed it with a grade of 8.00! <b style="text-align: justify; color: rgb(0, 0, 255);"> This year, over 100 students have registered for this course, which can be considered 
													as a record for a master robotic course at the University of Groningen!</b> </p> -->
												</p>
												</p>
												<!-- <ul class="actions">
													<li><a href="http://www.ai.rug.nl/hkasaei" target="_blank" class="button">More</a></li>
												</ul> -->
											</div>
										</article>
									</div>
									
									

									</section>
									<section>
									<header class="major">
										<h2 id="OR">Teaching Assistants</h2>
									</header>

									This year, the course has four TAs to help you during the practical sessions: <b>Andrei, Vlad, Andreea,</b> and <b>Klemen</b>. 
									We would be happy to assist you to the best of our abilities, so don't hesitate to ask if you have any questions.
								</br></br>

									<div class="row gtr-50 gtr-uniform">
										
										<div class="col-2">
											<!-- <a href="https://ieeexplore.ieee.org/document/9311749" target="_blank"> -->
											<a target="_blank">	
													<span class="image fit"><img src="images/andrei_photo.png" alt=""/>
													<p style="text-align: center; color: rgb(0, 0, 0);" > <b>Andrei Miculita</b>
														<br/> a.l.miculita@student.rug.nl </p>
												</span>
											</a>
										</div>
										<div class="col-0">
										</div>
										<!-- =============================================================================================== -->
										<div class="col-2">
											<!-- <a href="https://ieeexplore.ieee.org/document/9311749" target="_blank"> -->
											<a target="_blank">	
												<span class="image fit"><img src="images/vlad_photo.png" alt=""/>
												<p style="text-align: center; color: rgb(0, 0, 0);" ><b>Vlad Iftime</b>
														<br/> v.c.iftime@student.rug.nl </p>
												</span>
											</a>
										</div>
										<div class="col-0">
										</div>
										<!-- =============================================================================================== -->
										<div class="col-2">
											<!-- <a href="https://ieeexplore.ieee.org/document/9311749" target="_blank"> -->
											<a target="_blank">	
												<span class="image fit"><img src="images/andreea_photo.png" alt=""/>
												<p style="text-align: center; color: rgb(0, 0, 0);" ><b>  Andreea Toca	</b>
														<br/> a.toca@student.rug.nl </p>
												</span>
											</a>
										</div>
										<div class="col-0">
										</div>
										<!-- =============================================================================================== -->
										<div class="col-2">
											<!-- <a href="https://ieeexplore.ieee.org/document/9311749" target="_blank"> -->
											<a target="_blank">	
												<span class="image fit"><img src="images/klemen_photo.png" alt=""/>
												<p style="text-align: center; color: rgb(0, 0, 0);" ><b>Klemen Vončina</b>
														<br/> k.voncina@student.rug.nl </p>
												</span>
											</a>
										</div>
										<div class="col-0">
										</div>
										<!-- =============================================================================================== -->
										<div class="col-0">
										</div>
									<!-- <div class="posts">
										<article>
											<p style="text-align: justify;"> <span class="image left"><img src="images/thijs.png" alt=""></span> 
												<b style="color: rgb(0, 0, 0);">My name is Thijs Eker</b>. I'm a third year AI master student and am currently finishing my master thesis on ship classification. 
												I will be one of the TAs for this year's Cognitive Robotics course, if you have any questions don't hesitate to ask!
												<br><b style="color: rgb(0, 0, 200);"> Email: thijs.eker@gmail.com</b>										
											</p>												
										</article>
										<article>
											<p style="text-align: justify;"> <span class="image left"><img src="images/Georgios.png" alt=""></span> 
												<b style="color: rgb(0, 0, 0);">I am Georgios Tziafas</b>, a second year AI master student and an enthusiast of recent progress in the field of Machine Learning for Computer Vision and Natural Language Processing.
												My current work revolves mostly around Multi-Modal Learning for coupling visual perception to natural language understanding and inference, aiming at exciting AI applications for high-level interactive cognitive systems.
												Feel free to contact me!
												<br><b style="color: rgb(0, 0, 200);">Email: g.tziafas@student.rug.nl</b>
										
											</p>												
										</article>
										<article>
											<p style="text-align: justify;"> <span class="image left"><img src="images/Hamed.png" alt=""></span> 
												<b style="color: rgb(0, 0, 0);">I am Hamed Ayoobi</b>, a Ph.D researcher in ML, Computer Vision and Argumentation. 
												I am currently working on open-ended learning for 3D point cloud categorization and parts segmentation. 
												Moreover, I am working on a newly developed machine learning technique called Argumentaion-Based Learning (ABL). 
												I will be one of your TA's for Cognitive Robotics course and I would be happy to help you, if you have any questions.
												<br><b style="color: rgb(0, 0, 200);">Email: h.ayoobi@rug.nl</b>
											</p>												
										</article> -->

									</div>
								</section>								

							<!-- Section -->
								<section id="LO">
									<header class="major">
										<h2>Learning Objectives</h2>
									</header>
									<h3 style="text-align: justify; color: rgb(0, 0, 0);font-size: 22px;"> After successful completion of this course, students will be able to: </h3>
									<div class="features">
										<article>
											<span class="icon fa-diamond", style="color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Explain meaning of different concepts often used in the field of 3D object perception, grasping and 
													human robot interaction and their application in robotics.</p>												
											</div>
										</article>
										<article>
											<span class="icon fa-diamond", style="color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Explain the main theories of open-ended learning and cognitive robotics.</p>
											</div>
										</article>
										<article>
											<span class="icon fa-diamond", style=" color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Exploit deep transfer learning algorithms for open-ended object category learning and recognition.</p>
											</div>
										</article>
										<article>
											<span class="icon fa-diamond", style=" color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Implement and experiment several methods for object grasping.</p>
											</div>
										</article>
										<article>
											<span class="icon fa-diamond", style="color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Create a tight coupling between object perception and manipulation and perform experiment using real Kinect data
													and a simulated Panda robotic arm.</p>
											</div>
										</article>
										<article>
											<span class="icon fa-diamond", style="color: rgb(0, 0, 255);"></span>
											<div class="content">
												<p style="text-align: justify; color: rgb(0, 0, 0); ">Put hands-on experience working on a research project. It is expected that students will also gain the following 
													research skills: analyzing literature related to a particular topic, critiquing papers, and presentation of research ideas.</p>
											</div>
										</article>
									</div>
									

								</section>
								<!-- Section -->
								<section id="PQ">
										<header class="major">
											<h2>Prerequisites </h2>
										</header>
										<p style="text-align: justify; color: rgb(0, 0, 0); ">Prior knowledge of basic linear algebra is recommended, but not required. For programming throughout the course, 
											we mainly use C++/Python based ROS-melodic. For your final project, you are free to choose MATLAB, Python, or C++ as your coding language.
										</p>
								</section>
							<!-- Section -->
								<section id="CF">
									<header class="major">
										<h2>Class Format</h2>
									</header>
									<p style="text-align: justify; color: rgb(0, 0, 0); ">A cognitive robot should process very different types of information in varying time scales. Two different modes of 
										processing, generally labelled as System 1 and System 2, are commonly accepted theories in cognitive psychology. The operations of System 1 (i.e. perception and action) are typically fast,
										automatic, reactive and intuitive. The operations of System 2 (i.e. semantic) are slow, deliberative and analytic. 
										We recently wrote a survey paper about the 
										<b><a href = "https://rdcu.be/csdcK" target="_blank" class="external text" title="" rel="nofollow" style="color: rgb(0,0, 255);">State of Lifelong Learning in Service Robots</a></b>.
										It covers all the topics of the cognitive robotics course in a concise and brief manner to help students in easy remembrance and quick revision.

										</br></br>
										This year theme of the course is built on top of two important topics: <b><a href = "https://www.sciencedirect.com/science/article/pii/S0925231218302327" target="_blank" class="external text" title="" rel="nofollow" style="color: rgb(0,0, 255);">towards lifelong assistive robotics: a tight coupling between object perception and manipulation</a></b> 
										and <b><a href = "https://arxiv.org/pdf/2106.01866.pdf" target="_blank" class="external text" title="" rel="nofollow" style="color: rgb(0,0, 255);">simultaneous multi-view object grasping and recognition in open-ended domains</a></b>. 
										The course is a combination of lectures, reading sessions and robotic lab sessions. The lectures discuss the fundamentals of topics required to develop a cognitive robotic system mainly with
										the distinctive characteristics of System 1. During the reading sessions, students present and discuss recent contributions in the fields of object perception and manipulation. 
										See detailed contents, coursework and grading policies below.
									</p>
									<div class="posts">
										<article>
											<a href="#LT" class="image"><img src="images/pic01.jpg" alt="" /></a>
											<h3>Lectures</h3>
											<p style="text-align: justify;">Topics include Introduction to Cognitive Robotics, 3D Object Perception, Object Grasping and Manipulation, Planning, Human Robot Interaction, 
												Open-Ended Learning, Deep Transfer Learning, Evaluations, and Application to Assistive Robots.</p>
											<ul class="actions">
												<li><a href="#LT" class="button">Read More</a></li>
											</ul>
										</article>
										<article>
											<a href="#EA" class="image"><img src="images/pic02.jpg" alt="" /></a>
											<h3>Essay Assignment and Reading Sessions (15%)</h3>
											<p style="text-align: justify;"> An essay assignment (i.e., two pages <a href = "https://www.ieee.org/conferences/publishing/templates.html" target="_blank" style="color: rgb(0,0, 255);">IEEE conference format</a>)
												 has been designed to ensure all students will read important papers on 3D object perception, affordance
												 detection and manipulation.  All students will get a chance to present their essay.</p>
											<ul class="actions">
												<li><a href="#EA" class="button">Read More</a></li>
											</ul>
										</article>
										<article>
											<a href="#LW" class="image"><img src="images/pic03.jpg" alt="" /></a>
											<h3>Robotic Lab Sessions (35%) + Final Project (50%)</h3>
											<p style="text-align: justify;">Two practical assignments have been devised to provide hands-on experiences for fundamental theories (35%). During the practical sessions, 
												we will use the RACE framework to get more insight into different algorithms. Then, students will work together on a finall project (50%). </p>
											<ul class="actions">
												<li><a href="#LW" class="button">Read more</a></li> <!-- LW:LabWork -->
											</ul>
										</article>
										
									</div>
								</section>
							<!-- Section -->
								<section id="LT">
									<header class="major">
										<h2>List of Topics</h2>
									</header>
									<p style="text-align: justify; color: rgb(0, 0, 0); ">The preliminary schedule is provided below and is subject to change. </p>

									<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Session</th>
														<th>Description</th>
														<th>Date</th>
													</tr>
												</thead>
												<tbody>
																												
													<tr>
														<td>1</td>
														<td>Introduction to Cognitive Robotics</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>2</td>
														<td>3D Object Perception and Experience Extraction</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>3</td>
														<td> Reading Day</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>4</td>
														<td> Object Representation</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>5</td>
														<td> Open-Ended Object Category Learning and Recognition</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>6</td>
														<td> Reading Day</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>7</td>
														<td>Object Grasping and Manipulation</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>8</td>
														<td> Tight Coupling between Perception and Manipulation</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>9</td>
														<td> Final Projects Presentations</td>
														<td>TBD</td>
													</tr>
												</tbody>
											</table>
										</div>
									
								</section>
							<!-- Section -->
								<section id="CWQP">
										<header class="major">
											<h2>Coursework and Grading Policies</h2>
										</header>
										<p style="text-align: justify; color: rgb(0, 0, 0); ">Throughout the course, students will work partly individual and partly in groups of two on a related research project 
											that they present at the end of the course. The grading policy for this course is based on an essay assignment, practical works and a final project. Students will need to score at least
											 a 5.5 average, and will have to get at least a 5.0 on each component:
										</p>

										<!-- Essay assignment -->
										<h2 id="EA" style="color:  rgb(0, 0, 255);">1- Essay assignment (15%):</h2>
										
										<p style="text-align: justify;"><span class="image left"><img src="images/pic02.jpg" alt="" /></span> An essay assignment (i.e., two pages <a href = "https://www.ieee.org/conferences/publishing/templates.html" target="_blank" style="color: rgb(0,0, 255);">IEEE conference format</a>) has been 
											designed to ensure all students will read important papers on 3D object perception, affordance detection and manipulation. 
											All students will get a chance to present their essay throughout the class during the reading days. 
											Each group will presents the content of a (set of) relevant paper(s). 
											<b>The presenters need to send the essay of their reading assignments two dayes before the day of the class. </b> 
											As an example, if you are going to present your work on Wednesday, you need to submit your essay by midnight on Monday. </p>									
											<!-- Lists -->
											<h4>The grading policy for this assignment is based on a Rubric chart containing the following criteria (available on Nestor):</h4>
											<div class="row">
												<div class="col-20 col-30-small" >			
													<ul>
														<li style="color:  rgb(0, 0, 255);">Content/Delivery/Creativity/Organization/Ability to answer questions/Length of presentation/Overall	quality</li>
													</ul>
												</div>
											</div>
											<br>
											<p style="text-align: justify;"> Possible topics for the essay assignment include but not limited to the following: </p>

											<div class="table-wrapper">
													<table>
														<thead>
															<tr>
																<th>Topics</th>
																<th>Suggested Papers</th>																
															</tr>
														</thead>
														<tbody>
															
															<tr>
																<td>CNN Features</td>
																<td>Selecting CNN Features for Online Learning of 3D Objects; Multi-View Convolutional Neural Networks </td>																																
															</tr>
															<tr>
																<td>Deep Learning</td>
																<td>A survey on Deep Learning Advances on Different 3D Data Representations</td>																																
															</tr>																
															
															<!-- <tr>
																<td>3D Object Recognition</td>
																<td>OrthographicNet: A Deep Learning Approach for 3D Object Recognition in Open-Ended Domains</td>																																
															</tr> -->
															<tr>
																<td>Affordance Detection</td>
																<td>Affordance detection of tool parts from geometric features</td>										
															</tr>
															<tr>
																<td>Grasping and Object Manipulation</td>
																<td> Closing the Loop for Robotic Grasping: A Real-time, Generative Grasp Synthesis Approach</td>
															</tr>
															<tr>
																<td>Kinestectich Teaching</td>
																<td>Learning to Grasp Familiar Objects using Object View Recognition and Template Matching</td>
															</tr>
															<tr>
																<td>Kinestectich Teaching</td>
																<td>Learning of grasp selection based on shape-templates</td>
															</tr>
																														

															<tr>
																<td> Challenges of Collaborative Manipulation</td>
																<td> Interactive, Collaborative Robots: Challenges and Opportunities</td>
															</tr>
															<!-- <tr>
																<td> Point Cloud Library Tutorial</td>
																<td> 3D  is  here:  Point  Cloud  Library  (PCL)</td>
															</tr> -->
															<tr>
																<td> Visual Servoing</td>
																<td> Survey on Visual Servoing for Manipulation</td>
															</tr>
														
															<tr>
																<td> Assistive Robotics</td>
																<td> Robots for Humanity Using Assistive Robotics to Empower People with Disabilities</td>
															</tr>
															<tr>
																<td> Lessons from Babies</td>
																<td> The Development of Embodied Cognition: Six Lessons from Babies	</td>
															</tr>
															<tr>
																<td> Pile Manipulation</td>
																<td> Perceiving, Learning, and Exploiting Object Affordances for Autonomous Pile Manipulation	</td>
															</tr>
															<tr>
																<td> Pile Segmentation</td>
																<td> Interactive singulation of objects from a pile	</td>
															</tr>
															<tr>
																<td> Pile Segmentation</td>
																<td> Learning to Singulate Objects using a Push Proposal Network</td>
															</tr>
															<tr>
																<td> Dex-Net </td>
																<td> Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics </td>
															</tr>		
															<tr>
																<td> Grasp Pose Generator</td>
																<td> High precision grasp pose detection in dense clutter </td>
															</tr>		
															<tr>
																<td> ...</td>
																<td> ... </td>
															</tr>	

														</tbody>
													</table>
												</div>

										</p>
										<!-- 2- Practical assignment -->

										<h2 id="LW" style="color:  rgb(0, 0, 255); ">2- Practical assignments and report (35%):</h2>
										
										<p style="text-align: justify;">
											<!-- <span class="image right"><img src="images/pic03.jpg" alt="" id="LW" /></span><span class="image right"><img src="images/pic032.jpg" alt="" id="LW" /></span>  -->
											Two practical assignments have been devised to provide hands-on experiences for fundamental theories. 
											During the practical sessions, we will use the RACE framework, Gazebo, Rviz, MoveIt, and standard datasets to get more insight into different algorithms. Particularly, 
											students will work on a “clear_table” scenario using the RACE framework, which composes of two projects: </p>														
											<div class="row">
												<div class="col-10 col-30-small">
													<ul>
													<li> <b style="color: rgb(0, 0, 255);">Project1:</b> <b style="color: rgb(0, 0, 0);"> Open-Ended Learning Approaches for 3D Object Recognition. </b></li>
													<li> <b style="color: rgb(0, 0, 255);">Project2:</b> <b style="color: rgb(0, 0, 0);"> Coupling between Object Perception and Manipulation:
														Tracking and Grasping the Nearest Mug Object.</b></li>																	
													</ul>
												</div>
											</div>				
											<p style="text-align: justify;">For both projects, students are provided with stub of the code and are expected to complete it (see the details below).
												During the first and second assignments, students have to think about their final project, in particular, what they want to develop and if possible which comparisons they want to make. 
												
											</br></br>
											
												<b style="color: rgb(255, 0, 25);">*Note:</b> <b> At the end of each practical assignment a report (i.e., up to four pages <a href = "https://www.overleaf.com/latex/templates/ieee-conference-template-example/nsncsyjfmpxy" target="_blank" style="color: rgb(0,0, 255);">IEEE conference format</a>),
													including all the figures, tables, and references, has to be delivered.</b> These practical assignments prepare students to do the final course project. Please read the detailed description of each project below.</br>
												
												<p style = "text-align: justify;"><b style="color: rgb(0, 0, 255);">*Extra credit:</b> We will evaluate your object recognition system using an open-ended evaluation protocol. 
													We will add <b style="color: rgb(0, 0, 255);">0.5 point</b> to the final score of the student who achieves the highest performance, <b style="color: rgb(0, 0, 255);">0.35 point</b>  
													to the student who achieves the second place, and <b style="color: rgb(0, 0, 255);">0.20 point</b>  to the student who achieves third place. We will compute the performance 
													of your algorithm ourselves (code that does not run will be disqualified from the contest). This reward is designed to encourage you to experiment with different algorithms 
													and hyperparameter settings to obtain the best performance.</p>		
											<!-- Lists -->
											<h4>The grading policy for this assignment is based on a Rubric chart containing the following criteria (will be available on Nestor):</h4>
											<div class="row">
												<div class="col-20 col-30-small">

													<ul>
															
														<li style="color:  rgb(0, 0, 255);">Content/Delivery/Creativity and presentation/Organization/Neatness and attractiveness/Overall quality</li>
													
													</ul>
												</div>
											</div>				
											
										</br>
											<div class="posts">
													<article>
														<a class="image"><img src="images/pic033.jpg" alt="" /></a>
														<h4 style="text-align: justify;"> Setup the RACE framework and its dependencies	</h4>
														<p style="text-align: justify;">
																Here you will discover how easy it is to get started with the RACE framework.
																This tutorial is not meant to be a deep dive into the ROS functionalities or codes surrounding object perception and learning.
																If you’re interested in studying the framework in depth, including both (1) discussion of theories and (2) hands-on implementations, 
																check out <a href = "https://rugcognitiverobotics.github.io/documents/Hamidreza_Kasaei_PhD_thesis.pdf" target="_blank" style="color: rgb(0,0, 255);">my Ph.D. thesis</a>. 
 
														</p>
														<ul class="actions">
															<!-- <li><a href="https://rugcognitiverobotics.github.io/setup_2020.html" target="_blank" class="button">Read More</a></li> -->
															<!-- <li><a href="" target="_blank" class="button">Read More</a></li> -->
															<a class="button small" href="" target="_blank">Read More (html)</a> 

														</ul>
													</article>
													<article>
														<a href="https://youtu.be/iEq9TAaY9u8" target="_blank" class="image"><img src="images/pic032.jpg" alt="" /></a>
														<h4 style="text-align: justify;">[Project1] Open-Ended Learning Approaches for 3D Object Recognition</h4>
														<p style="text-align: justify;"> Human beings learn to recognize object categories ceaselessly over time. This ability to refine and extend knowledge from the set of 
															accumulated experiences facilitates the adaptation to new environments. In this project, studnets will learn how to create an object perception system 
															that can learn about 3D object categories in an open-ended fashion [<a href="https://youtu.be/iEq9TAaY9u8" target="_blank">see the example</a>].
														</p>
														<ul class="actions">
																<!-- <li><a href="https://youtu.be/iEq9TAaY9u8" target="_blank" class="button">Read More about Project 1</a></li> -->
																<!-- <li><a href="https://www.dropbox.com/s/6b0ibgcqor5j5eq/project1.pdf?dl=1" target="_blank"  class="button">Read More about Project 1 (PDF)</a></li> -->
																<!-- <li><a href="https://www.dropbox.com/s/pba0wwidf9yst2x/description_of_project2_2021.pdf?dl=1" target="_blank"  class="button">Read More about Project 1 (PDF)</a></li> -->

															<a class="button small" href="https://rugcognitiverobotics.github.io/documents/description_of_project2_2021_part1.pdf" target="_blank" > Part 1 (PDF) </a> 
															<a class="button small" href="https://rugcognitiverobotics.github.io/documents/description_of_project2_2021_part2.pdf" target="_blank"> Part 2 (PDF) </a> 
												
												
														</ul>
													</article>
													<article>
														<a href="https://youtu.be/6QNwps1TjWA" target="_blank" class="image"><img src="images/pic031.jpg" alt="" /></a>
														<h4 style="text-align: justify;">[Project2] Coupling between Object Perception and Manipulation </h4>
														<p style="text-align: justify;">In this project, students will work on a virtual reality scenario. In particular, a virtual Panda robotic arm works on the real-world environment.
															 The robot perceives the environment using a real Kinect camera; it has to detect, learn and recognize objects and then, grasp 
															 the object. Students will learn how to couple perception and manipulation [<a href="https://youtu.be/6QNwps1TjWA" target="_blank">see the example</a>].
															</p>

														<ul class="actions">
																
																<!-- <li><a href="https://youtu.be/6QNwps1TjWA" target="_blank" class="button">Read More about Project 2</a></li> -->
																<!-- <li><a href="https://www.dropbox.com/s/9mdgk028as5l8sm/project2.pdf?dl=1" target="_blank" class="button">Read More about Project 2 (PDF)</a></li> -->

																<a class="button small" href="" target="_blank">Read More about Project 2 (PDF)</a> 

														</ul>
													</article>
													
												</div>
											
										</p>

										<!-- 3- Final project -->
									</br>
										<h2 style="color:  rgb(0, 0, 255); ">3- Final project and report (50%):</h2>
										
										<p style="text-align: justify;"><span class="image left"><img src="images/pic04.jpg" alt="" id="LW" /></span> For the final project, students will work in groups of four on either a 
											specific research project (up to 25% materials can be borrowed from the previous assignments) or an in-depth literature survey (~20-30 relevant papers, organized by different features, 
											identifying gaps in the state of the art). Finally, each group will write a report with the structure of a scientific conference paper 
											(i.e., <b> 6+n pages</b> <a href = "https://www.overleaf.com/latex/templates/ieee-conference-template-example/nsncsyjfmpxy" target="_blank" style="color: rgb(0,0, 255);">IEEE 
											conference format</a>). The report material (including text, figures, tables, acknowledgment, etc.) must fit into 6 pages, while there is no page limit for the appendix/references (n pages) sections.  
											<b> Reports exceeding the (6+n) page limit will not be evaluated. </b> The last two sessions are dedicated to the final project presentations.
											Each group has to send a short description of the project (up to 2 paragraphs) to Hamidreza Kasaei (cognitiverobotic@gmail.com) to get feedback about the proposed project. This document should state:
										</p>														
											<div class="row">
												<div class="col-10 col-30-small">
													<ul>
														<li> Title of project, student names and student numbers,</li>
														<li> Explain the goal of the to-be-developed system,</li>
														<li> Explain how will you compare your approach with other state-of-the-art approaches if possible.</li>							
													</ul>
												</div>
											</div>									
											<p style="text-align: justify;"> Detailed information about the content of the report and the deadline will be posted later. Here is a short list of possible projects. 
												You may want to check out my list of projects and publications (see <a href = "http://www.ai.rug.nl/hkasaei" target = "_blank" style="color: rgb(0, 0, 255);">www.ai.rug.nl/hkasaei</a>).
												You could select one of the below topics, or come up with another project idea on your own.
 
												<div class="table-wrapper">
														<table>
															<tbody>
																								
																<tr>
																	<td>3D Object Recognition</td>
																	<td>OrthographicNet</td>	
																	<td>Challenges of Collaborative Manipulation</td>																															
																</tr>
																<tr>
																	<td>Affordance Detection</td>
																	<td>Segmentation of Cluttered Scenes</td>
																	<!-- Real-Time 3D Segmentation of Cluttered Scenes for Robot Grasping -->
																	<td>Cognitive Robotics</td>										
																</tr>
																<tr>
																	<td>Grasping and Object Manipulation</td>
																	<td> Pile Manipulation </td>
																	<td>Visual Servoing	</td>										
																</tr>
																<tr>
																	<td>Kinestectich Teaching</td>
																	<td>Deep Transfer Learning</td>
																	<td>Open-Ended (lifelong) Learing</td>										
																</tr>
																<tr>
																	<td>Assistive Robots</td>										
																	<td>Human-Robot Interaction</td>
																	<td>Eye-in-Hand and Eye-to-Hand System</td>										
																</tr>
															</tbody>
														</table>
													</div>
	
											<!-- Lists -->
											<h4>The grading policy for this assignment is based on a Rubric chart containing the following criteria (will be available on Nestor):</h4>
											<div class="row">
												<div class="col-20 col-30-small">

													<ul>
															
														<li style="color:  rgb(0, 0, 255);">Content/Delivery/Creativity and presentation/Organization/Neatness and attractiveness/Overall quality</li>
													
													</ul>
												</div>
											</div>				
										</section>
										<section id="Remarks">
													<header class="major">
														<h2>Rmarks</h2>
													</header>
													<div class="row">
														<div class="col-20 col-30-small">

															<ul>
																<li> <b>Late submissions</b> will lose <b>25%</b>, <b>50%</b>, and <b>100%</b> of the initial mark per day respectively. Therefore, having <b>0</b> marks on the third day after the deadline. 
																	You may submit your first practical assignment late (up to two days) with no penalty; this will be applied <b> ONLY to your first practical assignment</b>.
																<li>All the page limits <b>exclude</b> references.</li>
																<li>Feel free to collaborate on solving the problem but write your code individually. In particular, do not copy code from other students.</li>
															</ul>
														</div>
													</div>
													<!-- This class is partially based on the following existing courses:  -->
											<!-- <div class="row"> -->
													<!-- <div class="col-10 col-30-small"> -->
														<!-- <ul> -->
															<!-- <li> TBD.</li>																			 -->
														<!-- </ul> -->
													<!-- </div> -->
												<!-- </div>			 -->
										</p>
									</section>

							
							
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									
									<ul>
										
										<li><a href="#banner">Course Description</a></li>
										<li><a href="#CS">Course Staff</a></li>
										<li><a href="#LO">Learning Objectives</a></li>
										<!-- <li><a href="#PQ">Prerequisites</a></li> -->
										<li><a href="#CF">Class Format</a></li>
										<li><a href="#LT">List of Topic</a></li>
										<li><a href="#CWQP">Coursework and Grading Policies</a></li>
										<li><a href="#Remarks">Remarks</a></li>

									</ul>
								</nav>


							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p> <b style="color: rgb(255, 0, 0);">Hamidreza Kasaei</b> (Course Coordinator)</p>
									<ul class="contact">
										<li class="fa-envelope-o">hamidreza.kasaei@rug.nl</li>
										<li class="fa-dribbble"><a href="http://www.ai.rug.nl/hkasaei" target="_blank"> www.ai.rug.nl/hkasaei</a></li>
										<li class="fa-home">Office #340, Bernoulliborg building, University of Groningen.</li>
									</ul>
									<p> <b style="color: rgb(255, 0, 0);">Teaching Assistants</b>
									<ul class="contact">
										<!-- <li class="fa-envelope-o">cognitiverobotic@gmail.com</li> -->
										<li class="fa-envelope-o">a.l.miculita@student.rug.nl</li>
										<li class="fa-envelope-o">v.c.iftime@student.rug.nl</li>
										<li class="fa-envelope-o">a.toca@student.rug.nl</li>				
										<li class="fa-envelope-o">k.voncina@student.rug.nl</li>				

									<!--<li class="fa-home"><a href="#">Office #350, Bernoulliborg building, University of Groningen. </a></li>-->
									</ul>
				
								</section>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
